# 计划方案

## 1. 核心功能 core feature

- **获取光标上下文内容**  
  - 将光标所在位置之前的文本称作“上文（context）”  
  - 将光标所在位置之后要生成的文本称作“下文（continuation）”  

- **调用 LLM 进行文本补全**  
  - 每次尝试进行 text-autocompletion 时，使用“上文（context）”作为 `prompt` 调用 LLM 模型  
  - 生成的文本即为下文（continuation）候选  

## 2. 上下文长度和补全长度

- **上下文长度 (`length_context`)**  
  - 指定用于 prompt 的最大文本长度  
  - 可以在实验中进行不同取值来权衡性能、速度和准确性  

- **补全长度 (`length_continuation`)**  
  - 指定生成的文本长度上限  
  - 同样可作为实验中的可调参，用于评估不同长度对用户体验和质量的影响  

## 3. 可用的其他资料

1. **Fine-Tuning（改变模型参数）**  
   - 如果数据集高度特定于某个领域，且数据量足够大，可以考虑对基础模型进行微调  
   - 这样可能能够带来更连贯的、更加符合领域需求的生成效果  

2. **RAG（不改变模型参数）**  
   - 如果数据集很小（例如用户的个人笔记或少量文档），使用 RAG（Retrieval-Augmented Generation）会更方便  
   - 不需要改变基础模型，只需检索相关知识片段并将其添加到提示（prompt）中即可  
   - 可以在原有大模型语言能力的基础上，利用外部知识库来增强生成结果  

## 4. 利用用户历史行为数据

- **收集用户历史行为作为数据**  
  - 可能用于描述历史行为的数据：
    - 用户输入过的文本  
    - 多次接受或拒绝的文本  
    - 指针（光标）停留时间较长的位置（可能代表用户思考或对建议不满意）  
  - 收集数据并存储于日志？

- **每次生成补全时充分利用这些历史数据**  
  - 根据用户历史偏好，对推荐结果进行排序/加权  
  - 提高生成文本被接受的可能性  

## 5. 优化生成模型的可能方法

1. **拼接上下文**  
   - 在生成时将用户最近写的一段文本或关键上下文拼接至 prompt 前部  
   - 格式示例：  
     ```
     User previously wrote: ...
     Now user continues: ...
     ```
   - 在保证语义连贯的同时，减少重复信息或与历史上下文割裂的情况  

2. **Fine-Tuning / RLHF**  
   - 若收集到了大量“用户接受/拒绝”的标注数据，可以对模型进行微调或者利用**RLHF**（基于人类反馈的强化学习）  
   - **Fine-Tuning**：适合有大规模且较高质量的领域数据  
   - **RLHF**：利用用户对生成结果的反馈，进一步指导模型在生成时更符合用户期望  

3. **RAG**  
   - 对于小规模数据，可以将数据索引到向量库中，生成时检索最相关信息并将其融入 prompt  
   - 不需要重新训练模型，能快速结合外部知识并提升结果针对性  

---

## 6. 测试数据的构建与评估

为了合理评估模型在不同情形下的表现，需要构建多样化的测试数据。可以考虑以下策略来拆分上下文（context）与下文（continuation），并得到不同类型的评估数据集：

1. **随机截断**  
   - 在长文本中，随机选择一个位置作为上下文截断点，截取该点之前的文本作为 `context`，之后的文本作为 `continuation`  
   - 适用于评估模型在无明确边界提示时的预测能力  

2. **固定长度**  
   - 先指定一个固定长度 `L`，将文本的前 `L` 个 token 作为 `context`，随后 `L` 之后的部分作为 `continuation`  
   - 可用于测试模型在不同上下文长度下的性能表现  

3. **基于句子边界**  
   - 按照句子边界进行划分：将文本分成若干独立句子，并选择其中若干句用作 `context`，后续句子用作 `continuation`  
   - 可评估模型的句子级连贯性  

4. **自然断点**  
   - 在段落或双换行等自然断点处分割上下文与下文  
   - 反映更真实的写作场景，提高评估结果与实际使用情境的贴合度  

## Reference资料

- [How GitHub Copilot Works](https://blog.quastor.org/p/github-copilot-works)  
  一篇对GitHub copilot的工作原理深入探讨的博客，我们可以借鉴其a proxy for cleaning的思想。

- [BBC News All-Time Dataset on Hugging Face](https://huggingface.co/datasets/RealTimeData/bbc_news_alltime)  
  该demo项目的数据集

- [RocketNotes GitHub Repository](https://github.com/fynnfluegge/rocketnotes)  
  一个关于高效做笔记的开源项目 其中它也实现了text autocompletion功能。


以上方案旨在利用上下文内容及用户历史行为数据，基于多种技术路径（Fine-Tuning、RAG、RLHF 等）有效地优化文本自动补全功能。后续可根据实际需求与数据规模，在不同模块之间进行灵活组合与迭代。
